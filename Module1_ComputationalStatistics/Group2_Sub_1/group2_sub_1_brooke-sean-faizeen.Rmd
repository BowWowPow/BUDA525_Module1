---
title: "Group2_HW1_Submision_Brooke-Sean-Faizaan"
output: pdf_document
date: "2025-08-29"
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)


install.packages("ISLR") 
library(ISLR) 
dim(College) # rows, cols
help(College)

vStore <- matrix(0,18,1000) 

for(i in 1:10000)
{ 
  vStore[,i]=sample(Wage$wage,1000,replace=TRUE) 
}

---

install.packages("ISLR")
library(ISLR)
dim(College)
head(College)
# storeIntVar <- table$GetDataInTable


apps<-College$Apps
apps


# we run sampling distros based on loads of different seeds. 
# Each time we random this, we will get different sampling data. 
# working hard to then run the code multiple times to see the difference in
# variation 

# -- This is the old way -- 
set.seed(1337)

# setting up an empty var for use later. Delegates 
bootsApplications<-NULL

# writing as dplyr
library(dplyr)
for(j in 1:1000)
{
  # in this case, the '.' is specifically piping "Apps" into those positions. 
  # so we're sampling (apps, len(apps), replacement = true)
  # why we don't use mean(.) here is because mean already
  # expects our sample from apps. So mean(.) and mean() are identical
  my_samp=apps%>%sample(.,length(.),replace=TRUE)%>%mean()
  # Once we grab a single sample 
  bootsApplications<-c(bootsApplications,my_samp)
  print(bootsApplications)
}

hist(bootsApplications)
quantile(bootsApplications,c(.1,.9))

#---
#Solution 2 -- Using Methods
#---
# Learning methods so we can setup some more "generic" principles
# Make sure you all methods with method calls on first run to work. 
# Here's a sample method from https://www.w3schools.com/r/
hello_world <- function(){
    'Hello, World!'
}
# We're printing the method output, but this could also be completed
# with just calling hello_world() and having the print inside
print(hello_world())
# To undertand how t.test does it's double sided p-test.
help(t.test) 

# Global Variables. 
# We're setting up a function that allows for N iterations of sampling,
# Always picking a new seed each iteration - the nSeed controls total loops.
# maxSeed controls how big the seed will be from 1:maxSeed
# maxSampleLoop controls how many times we sample from our passed in model
# dataToSample holds the dataSet we are passing into our sampling. 
# ---
nSeeds <- 3
maxSeed <- 10000
maxSampleLoop <- 3
dataToSample <- College$Apps
# ---

tests <- NULL
allBootSamples <- NULL

sampleApps <- function(nSeeds, maxSeed, maxSampleLoop, dataToSample)
{
  seed <- sample(1:maxSeed,nSeeds) 
  for(i in 1:nSeeds) 
  {
    # Random Seed gen - will always random between 1:Max
    # this will do it nSeed times, so 3 currently
    
    set.seed(seed[i])
    print(paste("seed: ", i, " : ", seed[i]))
    bootsApplications<-NULL
    for(j in 1:maxSampleLoop)
    {
      my_samp=dataToSample%>%sample(.,length(.),replace=TRUE)%>%mean()
      # Once we grab a single sample 
      bootsApplications<-c(bootsApplications,my_samp)
      
    }
    print(paste("boots Vector from :", i, " : ",bootsApplications))
    # This weird lang has weirder encapsulation rules. <<- passes to the 
    # global variable and not a local one with <- while inside a func/method
    allBootSamples[i] <<- bootsApplications 
    # Storing all P-Tests into a vector of nSeed so that we can then do
    # more math on it afterwards/compare and contrast. 
    tests[i] <<- t.test(bootsApplications, mu = 0)
  }
  for(i in 1:nSeeds)
  {
    print(tests[i]$p.value)
  }
}
sampleApps(nSeeds, maxSeed, maxSampleLoop, dataToSample)
traceback()
# We will use P-testing two ways ~ 



``` 